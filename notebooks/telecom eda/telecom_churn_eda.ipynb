{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Telecom Customer Churn EDA\n",
    "This script performs a comprehensive Exploratory Data Analysis (EDA) on the Telecom Customer Churn dataset\n",
    "following MLOps best practices.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import missingno as msno\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load and return the telecom churn dataset.\"\"\"\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        df = pd.read_csv(r'C:\\Users\\marwan\\Desktop\\mlops_final\\notebooks\\telecom eda\\telecom.csv')\n",
    "        print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: telecom.csv not found in the current directory.\")\n",
    "        print(\"Please make sure the file exists in the notebooks directory.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_inspection(df):\n",
    "    \"\"\"Perform initial data inspection.\"\"\"\n",
    "    if df is None:\n",
    "        return\n",
    "        \n",
    "    print(\"\\n=== Initial Data Inspection ===\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\nColumn Information:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\nBasic Statistics:\")\n",
    "    print(df.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values(df):\n",
    "    \"\"\"Analyze missing values in the dataset.\"\"\"\n",
    "    if df is None:\n",
    "        return\n",
    "        \n",
    "    print(\"\\n=== Missing Value Analysis ===\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percentage = (missing_values / len(df)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Values': missing_values,\n",
    "        'Percentage': missing_percentage\n",
    "    })\n",
    "    missing_df = missing_df[missing_df['Missing Values'] > 0].sort_values('Percentage', ascending=False)\n",
    "    \n",
    "    if len(missing_df) > 0:\n",
    "        print(\"\\nMissing Value Statistics:\")\n",
    "        print(missing_df)\n",
    "    else:\n",
    "        print(\"\\nNo missing values found in the dataset.\")\n",
    "    \n",
    "    # Create missing value visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    msno.matrix(df)\n",
    "    plt.title('Missing Values Matrix')\n",
    "    plt.savefig('missing_values_matrix.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_categorical_features(df):\n",
    "    \"\"\"Analyze categorical features in the dataset.\"\"\"\n",
    "    if df is None:\n",
    "        return\n",
    "        \n",
    "    print(\"\\n=== Categorical Feature Analysis ===\")\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        print(f\"\\nUnique values in {col}:\")\n",
    "        print(df[col].value_counts())\n",
    "        \n",
    "        # Create bar plot for categorical features\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(data=df, x=col)\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'categorical_{col}_distribution.png')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_numerical_features(df):\n",
    "    \"\"\"Analyze numerical features in the dataset.\"\"\"\n",
    "    if df is None:\n",
    "        return\n",
    "        \n",
    "    print(\"\\n=== Numerical Feature Analysis ===\")\n",
    "    \n",
    "    # Get numerical columns excluding the target\n",
    "    numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    \n",
    "    # Create distribution plots for numerical features\n",
    "    n_cols = 3\n",
    "    n_rows = (len(numerical_columns) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, col in enumerate(numerical_columns):\n",
    "        sns.histplot(data=df, x=col, hue='Churn', ax=axes[idx])\n",
    "        axes[idx].set_title(f'Distribution of {col}')\n",
    "    \n",
    "    # Remove empty subplots\n",
    "    for idx in range(len(numerical_columns), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('numerical_features_distribution.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_correlations(df):\n",
    "    \"\"\"Analyze correlations between features.\"\"\"\n",
    "    if df is None:\n",
    "        return\n",
    "        \n",
    "    print(\"\\n=== Correlation Analysis ===\")\n",
    "    \n",
    "    # Create a copy of the dataframe for correlation analysis\n",
    "    df_corr = df.copy()\n",
    "    \n",
    "    # Convert categorical variables to numeric for correlation analysis\n",
    "    le = LabelEncoder()\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_columns:\n",
    "        df_corr[col] = le.fit_transform(df_corr[col].astype(str))\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = df_corr.corr()\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('correlation_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot correlation with target variable\n",
    "    target_correlations = correlation_matrix['Churn'].sort_values(ascending=False)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=target_correlations.values, y=target_correlations.index)\n",
    "    plt.title('Feature Correlations with Churn')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('target_correlations.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(df):\n",
    "    \"\"\"Analyze feature importance using Random Forest.\"\"\"\n",
    "    if df is None:\n",
    "        return\n",
    "        \n",
    "    print(\"\\n=== Feature Importance Analysis ===\")\n",
    "    \n",
    "    # Create a copy of the dataframe for feature importance analysis\n",
    "    df_importance = df.copy()\n",
    "    \n",
    "    # Convert categorical variables to numeric\n",
    "    le = LabelEncoder()\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_columns:\n",
    "        if col != 'Churn':  # Don't encode the target column yet\n",
    "            df_importance[col] = le.fit_transform(df_importance[col].astype(str))\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = df_importance.drop('Churn', axis=1)\n",
    "    y = le.fit_transform(df_importance['Churn'])\n",
    "    \n",
    "    # Train a Random Forest model\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Get feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': rf.feature_importances_\n",
    "    })\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=feature_importance, x='importance', y='feature')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_quality(df):\n",
    "    \"\"\"Perform data quality checks.\"\"\"\n",
    "    if df is None:\n",
    "        return\n",
    "        \n",
    "    print(\"\\n=== Data Quality Checks ===\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"\\nNumber of duplicate rows: {duplicates}\")\n",
    "    \n",
    "    # Check for outliers using IQR method\n",
    "    def detect_outliers(df, column):\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)][column]\n",
    "        return len(outliers)\n",
    "    \n",
    "    numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    outlier_summary = pd.DataFrame({\n",
    "        'Column': numerical_columns,\n",
    "        'Outliers': [detect_outliers(df, col) for col in numerical_columns]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nOutlier Summary:\")\n",
    "    print(outlier_summary)\n",
    "    \n",
    "    # Check for class balance\n",
    "    class_balance = df['Churn'].value_counts(normalize=True) * 100\n",
    "    print(f\"\\nClass Balance for Churn:\")\n",
    "    print(class_balance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully. Shape: (7043, 37)\n",
      "\n",
      "=== Initial Data Inspection ===\n",
      "\n",
      "First few rows:\n",
      "   CustomerID  Gender  Age Married  NumberofDependents          City  ZipCode  \\\n",
      "0  0002-ORFBO  Female   37     Yes                   0  Frazier Park    93225   \n",
      "1  0003-MKNFE    Male   46      No                   0      Glendale    91206   \n",
      "2  0004-TLHLJ    Male   50      No                   0    Costa Mesa    92627   \n",
      "3  0011-IGKFF    Male   78     Yes                   0      Martinez    94553   \n",
      "4  0013-EXCHZ  Female   75     Yes                   0     Camarillo    93010   \n",
      "\n",
      "   Population  NumberofReferrals  TenureinMonths  ...    PaymentMethod  \\\n",
      "0        4498                  2               9  ...      Credit Card   \n",
      "1       31297                  0               9  ...      Credit Card   \n",
      "2       62069                  0               4  ...  Bank Withdrawal   \n",
      "3       46677                  1              13  ...  Bank Withdrawal   \n",
      "4       42853                  3               3  ...      Credit Card   \n",
      "\n",
      "  MonthlyCharge  TotalCharges TotalRefunds TotalExtraDataCharges  \\\n",
      "0          65.6        593.30         0.00                     0   \n",
      "1          -4.0        542.40        38.33                    10   \n",
      "2          73.9        280.85         0.00                     0   \n",
      "3          98.0       1237.85         0.00                     0   \n",
      "4          83.9        267.40         0.00                     0   \n",
      "\n",
      "  TotalLongDistanceCharges  TotalRevenue    Churn    ChurnCategory  \\\n",
      "0                   381.51        974.81   Stayed              NaN   \n",
      "1                    96.21        610.28   Stayed              NaN   \n",
      "2                   134.60        415.45  Churned       Competitor   \n",
      "3                   361.66       1599.51  Churned  Dissatisfaction   \n",
      "4                    22.14        289.54  Churned  Dissatisfaction   \n",
      "\n",
      "                     ChurnReason  \n",
      "0                            NaN  \n",
      "1                            NaN  \n",
      "2  Competitor had better devices  \n",
      "3        Product dissatisfaction  \n",
      "4            Network reliability  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "\n",
      "Column Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 37 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   CustomerID                     7043 non-null   object \n",
      " 1   Gender                         7043 non-null   object \n",
      " 2   Age                            7043 non-null   int64  \n",
      " 3   Married                        7043 non-null   object \n",
      " 4   NumberofDependents             7043 non-null   int64  \n",
      " 5   City                           7043 non-null   object \n",
      " 6   ZipCode                        7043 non-null   int64  \n",
      " 7   Population                     7043 non-null   int64  \n",
      " 8   NumberofReferrals              7043 non-null   int64  \n",
      " 9   TenureinMonths                 7043 non-null   int64  \n",
      " 10  Offer                          3166 non-null   object \n",
      " 11  PhoneService                   7043 non-null   object \n",
      " 12  AvgMonthlyLongDistanceCharges  6361 non-null   float64\n",
      " 13  MultipleLines                  6361 non-null   object \n",
      " 14  InternetService                7043 non-null   object \n",
      " 15  InternetType                   5517 non-null   object \n",
      " 16  AvgMonthlyGBDownload           5517 non-null   float64\n",
      " 17  OnlineSecurity                 5517 non-null   object \n",
      " 18  OnlineBackup                   5517 non-null   object \n",
      " 19  DeviceProtectionPlan           5517 non-null   object \n",
      " 20  PremiumTechSupport             5517 non-null   object \n",
      " 21  StreamingTV                    5517 non-null   object \n",
      " 22  StreamingMovies                5517 non-null   object \n",
      " 23  StreamingMusic                 5517 non-null   object \n",
      " 24  UnlimitedData                  5517 non-null   object \n",
      " 25  Contract                       7043 non-null   object \n",
      " 26  PaperlessBilling               7043 non-null   object \n",
      " 27  PaymentMethod                  7043 non-null   object \n",
      " 28  MonthlyCharge                  7043 non-null   float64\n",
      " 29  TotalCharges                   7043 non-null   float64\n",
      " 30  TotalRefunds                   7043 non-null   float64\n",
      " 31  TotalExtraDataCharges          7043 non-null   int64  \n",
      " 32  TotalLongDistanceCharges       7043 non-null   float64\n",
      " 33  TotalRevenue                   7043 non-null   float64\n",
      " 34  Churn                          7043 non-null   object \n",
      " 35  ChurnCategory                  1869 non-null   object \n",
      " 36  ChurnReason                    1869 non-null   object \n",
      "dtypes: float64(7), int64(7), object(23)\n",
      "memory usage: 2.0+ MB\n",
      "None\n",
      "\n",
      "Basic Statistics:\n",
      "        CustomerID Gender          Age Married  NumberofDependents  \\\n",
      "count         7043   7043  7043.000000    7043         7043.000000   \n",
      "unique        7043      2          NaN       2                 NaN   \n",
      "top     0002-ORFBO   Male          NaN      No                 NaN   \n",
      "freq             1   3555          NaN    3641                 NaN   \n",
      "mean           NaN    NaN    46.509726     NaN            0.468692   \n",
      "std            NaN    NaN    16.750352     NaN            0.962802   \n",
      "min            NaN    NaN    19.000000     NaN            0.000000   \n",
      "25%            NaN    NaN    32.000000     NaN            0.000000   \n",
      "50%            NaN    NaN    46.000000     NaN            0.000000   \n",
      "75%            NaN    NaN    60.000000     NaN            0.000000   \n",
      "max            NaN    NaN    80.000000     NaN            9.000000   \n",
      "\n",
      "               City       ZipCode     Population  NumberofReferrals  \\\n",
      "count          7043   7043.000000    7043.000000        7043.000000   \n",
      "unique         1106           NaN            NaN                NaN   \n",
      "top     Los Angeles           NaN            NaN                NaN   \n",
      "freq            293           NaN            NaN                NaN   \n",
      "mean            NaN  93486.070567   22139.603294           1.951867   \n",
      "std             NaN   1856.767505   21152.392837           3.001199   \n",
      "min             NaN  90001.000000      11.000000           0.000000   \n",
      "25%             NaN  92101.000000    2344.000000           0.000000   \n",
      "50%             NaN  93518.000000   17554.000000           0.000000   \n",
      "75%             NaN  95329.000000   36125.000000           3.000000   \n",
      "max             NaN  96150.000000  105285.000000          11.000000   \n",
      "\n",
      "        TenureinMonths  ...    PaymentMethod MonthlyCharge  TotalCharges  \\\n",
      "count      7043.000000  ...             7043   7043.000000   7043.000000   \n",
      "unique             NaN  ...                3           NaN           NaN   \n",
      "top                NaN  ...  Bank Withdrawal           NaN           NaN   \n",
      "freq               NaN  ...             3909           NaN           NaN   \n",
      "mean         32.386767  ...              NaN     63.596131   2280.381264   \n",
      "std          24.542061  ...              NaN     31.204743   2266.220462   \n",
      "min           1.000000  ...              NaN    -10.000000     18.800000   \n",
      "25%           9.000000  ...              NaN     30.400000    400.150000   \n",
      "50%          29.000000  ...              NaN     70.050000   1394.550000   \n",
      "75%          55.000000  ...              NaN     89.750000   3786.600000   \n",
      "max          72.000000  ...              NaN    118.750000   8684.800000   \n",
      "\n",
      "       TotalRefunds TotalExtraDataCharges TotalLongDistanceCharges  \\\n",
      "count   7043.000000           7043.000000              7043.000000   \n",
      "unique          NaN                   NaN                      NaN   \n",
      "top             NaN                   NaN                      NaN   \n",
      "freq            NaN                   NaN                      NaN   \n",
      "mean       1.962182              6.860713               749.099262   \n",
      "std        7.902614             25.104978               846.660055   \n",
      "min        0.000000              0.000000                 0.000000   \n",
      "25%        0.000000              0.000000                70.545000   \n",
      "50%        0.000000              0.000000               401.440000   \n",
      "75%        0.000000              0.000000              1191.100000   \n",
      "max       49.790000            150.000000              3564.720000   \n",
      "\n",
      "        TotalRevenue   Churn ChurnCategory                    ChurnReason  \n",
      "count    7043.000000    7043          1869                           1869  \n",
      "unique           NaN       3             5                             20  \n",
      "top              NaN  Stayed    Competitor  Competitor had better devices  \n",
      "freq             NaN    4720           841                            313  \n",
      "mean     3034.379056     NaN           NaN                            NaN  \n",
      "std      2865.204542     NaN           NaN                            NaN  \n",
      "min        21.360000     NaN           NaN                            NaN  \n",
      "25%       605.610000     NaN           NaN                            NaN  \n",
      "50%      2108.640000     NaN           NaN                            NaN  \n",
      "75%      4801.145000     NaN           NaN                            NaN  \n",
      "max     11979.340000     NaN           NaN                            NaN  \n",
      "\n",
      "[11 rows x 37 columns]\n",
      "\n",
      "=== Missing Value Analysis ===\n",
      "\n",
      "Missing Value Statistics:\n",
      "                               Missing Values  Percentage\n",
      "ChurnCategory                            5174   73.463013\n",
      "ChurnReason                              5174   73.463013\n",
      "Offer                                    3877   55.047565\n",
      "InternetType                             1526   21.666903\n",
      "AvgMonthlyGBDownload                     1526   21.666903\n",
      "OnlineSecurity                           1526   21.666903\n",
      "OnlineBackup                             1526   21.666903\n",
      "DeviceProtectionPlan                     1526   21.666903\n",
      "PremiumTechSupport                       1526   21.666903\n",
      "StreamingTV                              1526   21.666903\n",
      "StreamingMovies                          1526   21.666903\n",
      "StreamingMusic                           1526   21.666903\n",
      "UnlimitedData                            1526   21.666903\n",
      "AvgMonthlyLongDistanceCharges             682    9.683374\n",
      "MultipleLines                             682    9.683374\n",
      "\n",
      "=== Categorical Feature Analysis ===\n",
      "\n",
      "Unique values in CustomerID:\n",
      "CustomerID\n",
      "0002-ORFBO    1\n",
      "6616-AALSR    1\n",
      "6625-UTXEW    1\n",
      "6625-IUTTT    1\n",
      "6625-FLENO    1\n",
      "             ..\n",
      "3352-RICWQ    1\n",
      "3352-ALMCK    1\n",
      "3351-NQLDI    1\n",
      "3351-NGXYI    1\n",
      "9995-HOTOH    1\n",
      "Name: count, Length: 7043, dtype: int64\n",
      "\n",
      "Unique values in Gender:\n",
      "Gender\n",
      "Male      3555\n",
      "Female    3488\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in Married:\n",
      "Married\n",
      "No     3641\n",
      "Yes    3402\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in City:\n",
      "City\n",
      "Los Angeles         293\n",
      "San Diego           285\n",
      "San Jose            112\n",
      "Sacramento          108\n",
      "San Francisco       104\n",
      "                   ... \n",
      "Johannesburg          2\n",
      "South Lake Tahoe      2\n",
      "Jacumba               2\n",
      "Holtville             2\n",
      "Eldridge              2\n",
      "Name: count, Length: 1106, dtype: int64\n",
      "\n",
      "Unique values in Offer:\n",
      "Offer\n",
      "Offer B    824\n",
      "Offer E    805\n",
      "Offer D    602\n",
      "Offer A    520\n",
      "Offer C    415\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in PhoneService:\n",
      "PhoneService\n",
      "Yes    6361\n",
      "No      682\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in MultipleLines:\n",
      "MultipleLines\n",
      "No     3390\n",
      "Yes    2971\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in InternetService:\n",
      "InternetService\n",
      "Yes    5517\n",
      "No     1526\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in InternetType:\n",
      "InternetType\n",
      "Fiber Optic    3035\n",
      "DSL            1652\n",
      "Cable           830\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in OnlineSecurity:\n",
      "OnlineSecurity\n",
      "No     3498\n",
      "Yes    2019\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in OnlineBackup:\n",
      "OnlineBackup\n",
      "No     3088\n",
      "Yes    2429\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in DeviceProtectionPlan:\n",
      "DeviceProtectionPlan\n",
      "No     3095\n",
      "Yes    2422\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in PremiumTechSupport:\n",
      "PremiumTechSupport\n",
      "No     3473\n",
      "Yes    2044\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in StreamingTV:\n",
      "StreamingTV\n",
      "No     2810\n",
      "Yes    2707\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in StreamingMovies:\n",
      "StreamingMovies\n",
      "No     2785\n",
      "Yes    2732\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in StreamingMusic:\n",
      "StreamingMusic\n",
      "No     3029\n",
      "Yes    2488\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in UnlimitedData:\n",
      "UnlimitedData\n",
      "Yes    4745\n",
      "No      772\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in Contract:\n",
      "Contract\n",
      "Month-to-Month    3610\n",
      "Two Year          1883\n",
      "One Year          1550\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in PaperlessBilling:\n",
      "PaperlessBilling\n",
      "Yes    4171\n",
      "No     2872\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in PaymentMethod:\n",
      "PaymentMethod\n",
      "Bank Withdrawal    3909\n",
      "Credit Card        2749\n",
      "Mailed Check        385\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in Churn:\n",
      "Churn\n",
      "Stayed     4720\n",
      "Churned    1869\n",
      "Joined      454\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in ChurnCategory:\n",
      "ChurnCategory\n",
      "Competitor         841\n",
      "Dissatisfaction    321\n",
      "Attitude           314\n",
      "Price              211\n",
      "Other              182\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in ChurnReason:\n",
      "ChurnReason\n",
      "Competitor had better devices                313\n",
      "Competitor made better offer                 311\n",
      "Attitude of support person                   220\n",
      "Don't know                                   130\n",
      "Competitor offered more data                 117\n",
      "Competitor offered higher download speeds    100\n",
      "Attitude of service provider                  94\n",
      "Price too high                                78\n",
      "Product dissatisfaction                       77\n",
      "Network reliability                           72\n",
      "Long distance charges                         64\n",
      "Service dissatisfaction                       63\n",
      "Moved                                         46\n",
      "Extra data charges                            39\n",
      "Limited range of services                     37\n",
      "Poor expertise of online support              31\n",
      "Lack of affordable download/upload speed      30\n",
      "Lack of self-service on Website               29\n",
      "Poor expertise of phone support               12\n",
      "Deceased                                       6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Numerical Feature Analysis ===\n",
      "\n",
      "=== Correlation Analysis ===\n",
      "\n",
      "=== Feature Importance Analysis ===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEDA could not be completed due to missing data file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m analyze_numerical_features(df)\n\u001b[0;32m     16\u001b[0m analyze_correlations(df)\n\u001b[1;32m---> 17\u001b[0m \u001b[43manalyze_feature_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m check_data_quality(df)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEDA completed successfully! All plots have been saved in the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meda_plots\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 24\u001b[0m, in \u001b[0;36manalyze_feature_importance\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Train a Random Forest model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Get feature importance\u001b[39;00m\n\u001b[0;32m     27\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m'\u001b[39m: rf\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m     30\u001b[0m })\n",
      "File \u001b[1;32mc:\\Windows\\System32\\venv38\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Windows\\System32\\venv38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Windows\\System32\\venv38\\lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Windows\\System32\\venv38\\lib\\site-packages\\sklearn\\utils\\validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[1;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Windows\\System32\\venv38\\lib\\site-packages\\sklearn\\utils\\validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    954\u001b[0m         )\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 957\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Windows\\System32\\venv38\\lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Windows\\System32\\venv38\\lib\\site-packages\\sklearn\\utils\\validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the EDA.\"\"\"\n",
    "    # Create output directory for plots\n",
    "    os.makedirs('eda_plots', exist_ok=True)\n",
    "    os.chdir('eda_plots')\n",
    "    \n",
    "    # Load data\n",
    "    df = load_data()\n",
    "    \n",
    "    if df is not None:\n",
    "        # Perform EDA\n",
    "        initial_inspection(df)\n",
    "        analyze_missing_values(df)\n",
    "        analyze_categorical_features(df)\n",
    "        analyze_numerical_features(df)\n",
    "        analyze_correlations(df)\n",
    "        analyze_feature_importance(df)\n",
    "        check_data_quality(df)\n",
    "        \n",
    "        print(\"\\nEDA completed successfully! All plots have been saved in the 'eda_plots' directory.\")\n",
    "    else:\n",
    "        print(\"\\nEDA could not be completed due to missing data file.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
